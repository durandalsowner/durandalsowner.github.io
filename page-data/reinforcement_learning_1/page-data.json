{"componentChunkName":"component---node-modules-lekoarts-gatsby-theme-minimal-blog-core-src-templates-post-query-tsx","path":"/reinforcement_learning_1","result":{"data":{"post":{"__typename":"MdxPost","slug":"/reinforcement_learning_1","title":"Reinforcement Learning 1","date":"02.07.2020","tags":[{"name":"Reinforcement Learning","slug":"reinforcement-learning"},{"name":"Machine Learning","slug":"machine-learning"}],"description":"learning note to recap knowledges about reinforcement learning","body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Reinforcement Learning 1\",\n  \"date\": \"2020-07-02T00:00:00.000Z\",\n  \"description\": \"learning note to recap knowledges about reinforcement learning\",\n  \"tags\": [\"Reinforcement Learning\", \"Machine Learning\"],\n  \"slug\": \"/reinforcement_learning_1\"\n};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h3\", null, \"Background\"), mdx(\"p\", null, \"Related course - Mobile and Cloud Computing Seminor.\\nIt was a research of different reinforcement learning frameworks in cloud resource management.\\nDue to covid-19 most of the readings and research works were done remotely.\\nNevertheless, it was fun and worth to learn this old but not obsolete concept!\"), mdx(\"hr\", null), mdx(\"h3\", null, \"What is RL?\"), mdx(\"p\", null, \"So what is Reinforcement Learning(RL)?\"), mdx(\"p\", null, \"definition:\"), mdx(\"p\", null, \"It is an intelligent agent model with online learning through interacting with the environment by taking certain actions based on rewards considerations.\\nAn online learning means the agent is learning while trying.\"), mdx(\"p\", null, \"In this article, I try not to include any mathematical formulas but introduce some conceptual basics.\"), mdx(\"p\", null, \"To make it easier to understand, we now simply define some definitions for a RL model as  an example as below.\"), mdx(\"p\", null, \"Agent: a baby\"), mdx(\"p\", null, \"Environment: baby's mum\"), mdx(\"p\", null, \"Action lists: crying, laughing, pressing stomach\"), mdx(\"p\", null, \"Rewards: food\"), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"960px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"79.58333333333334%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAQABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAQAF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAAB3xBqP//EABQQAQAAAAAAAAAAAAAAAAAAACD/2gAIAQEAAQUCX//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABQQAQAAAAAAAAAAAAAAAAAAACD/2gAIAQEABj8CX//EABgQAQADAQAAAAAAAAAAAAAAAAABECFx/9oACAEBAAE/IXG3D//aAAwDAQACAAMAAAAQBA//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAbEAEAAgMBAQAAAAAAAAAAAAABACERMZFRgf/aAAgBAQABPxBTm4ei2FLD5HJqW7Dkyxc//9k=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"img\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Baby-Mum-Food Example\",\n    \"title\": \"Baby-Mum-Food Example\",\n    \"src\": \"/static/216e1e7a6d108313578763bbc3f48443/18e3b/babymumexample.jpg\",\n    \"srcSet\": [\"/static/216e1e7a6d108313578763bbc3f48443/46946/babymumexample.jpg 240w\", \"/static/216e1e7a6d108313578763bbc3f48443/55489/babymumexample.jpg 480w\", \"/static/216e1e7a6d108313578763bbc3f48443/18e3b/babymumexample.jpg 960w\", \"/static/216e1e7a6d108313578763bbc3f48443/b9cfd/babymumexample.jpg 972w\"],\n    \"sizes\": \"(max-width: 960px) 100vw, 960px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  })), \"\\n    \")), mdx(\"p\", null, \"So here is our problem, how does the baby in the above scenario get the food?\"), mdx(\"p\", null, \"As a baby who still could not say hungry, it has 3 kinds of action to choose from\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"crying\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"smiling\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"pressing stomach\"))), mdx(\"p\", null, \"Now the question is that what would it choose to do first?\"), mdx(\"p\", null, \"When it doesn't know anything, it would try, try different actions randomly.\\nSince the baby has no infomration about the 3 actions, then the expectation value of each action should be the same at initial.\"), mdx(\"p\", null, \"This is the exploration process of reinforcement learning - to try actions randomly and see what will happen.\"), mdx(\"p\", null, \"Let's say the following scenario:\"), mdx(\"hr\", null), mdx(\"p\", null, \"1)  baby laughs, then no food\"), mdx(\"p\", null, \"2) baby cries, then no food\"), mdx(\"p\", null, \"3) baby presses stomach, then mum gives food\"), mdx(\"hr\", null), mdx(\"p\", null, \"Then the reward the baby gets from her action-laugh is nothing but her mum's laughing.\"), mdx(\"p\", null, \"Here, the baby learns, it will remember that laughing seems not working to show her hunger.\"), mdx(\"p\", null, \"In a RL model, we would want to update the expectation value of the action - laughing\\nso that this action would be less preferable in the future.\"), mdx(\"p\", null, \"After trying different actions, their expectation values would be updated.\"), mdx(\"p\", null, \"Here we may want to know\"), mdx(\"p\", null, \"what if the baby looks weak / tired?\"), mdx(\"p\", null, \"What if her mum is busy with other things?\"), mdx(\"p\", null, \"There are many other temporary factors which would probably affect the results of different actions.\\nSurely, it is good to add them to the model.\"), mdx(\"p\", null, \"In next chapter, I will introduce the concept of \\\"STATE\\\".\"), mdx(\"p\", null, \"Will add the next article link here \\\"Reinforcement Learning 2\\\"\"), mdx(\"p\", null, \"Recommended reading:\"), mdx(\"a\", {\n    href: \"https://www.geeksforgeeks.org/what-is-reinforcement-learning/\"\n  }, \"geeksforgeeks - Reinforcement learning\"), mdx(\"p\", null, \"Last edited: 16/07/2020\"), mdx(\"hr\", null));\n}\n;\nMDXContent.isMDXComponent = true;","excerpt":"Background Related course - Mobile and Cloud Computing Seminor.\nIt was a research of different reinforcement learning frameworks in cloudâ€¦","timeToRead":2,"banner":null}},"pageContext":{"slug":"/reinforcement_learning_1","formatString":"DD.MM.YYYY"}}}